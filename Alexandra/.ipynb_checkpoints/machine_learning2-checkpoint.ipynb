{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "## uses dummy variables to avoid missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neuro = pd.read_csv(\"all_neuron_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign all hippocampus neurons an area of Hippocampus\n",
    "words = [\"CA1\", \"CA3\"]\n",
    "for i, row in neuro.iterrows():\n",
    "    if any(word in row[\"Cell Type\"] for word in words):\n",
    "#         print(\"true\")0\n",
    "        neuro.loc[i, \"Area\"] = \"Hippocampus\"\n",
    "#         row[\"Area\"] = \"Hippocampus\"\n",
    "    else:\n",
    "        neuro.loc[i, \"Area\"] = \"other\"\n",
    "        row[\"Area\"] = \"other\"\n",
    "#     print(row[\"Cell Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_df = pd.get_dummies(neuro, columns=[\"Measurement\"])\n",
    "categorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hippo_df = categorized_df.loc[categorized_df[\"Area\"] == \"Hippocampus\"]\n",
    "X=hippo_df.drop([\"Cell Type\", \"Area\"], axis=1)\n",
    "y=hippo_df[\"Cell Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1, stratify=y)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=53))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " - 1s - loss: 1.7849 - acc: 0.5990\n",
      "Epoch 2/60\n",
      " - 0s - loss: 1.3934 - acc: 0.6396\n",
      "Epoch 3/60\n",
      " - 0s - loss: 1.3231 - acc: 0.6417\n",
      "Epoch 4/60\n",
      " - 0s - loss: 1.3016 - acc: 0.6396\n",
      "Epoch 5/60\n",
      " - 0s - loss: 1.2848 - acc: 0.6403\n",
      "Epoch 6/60\n",
      " - 0s - loss: 1.2702 - acc: 0.6417\n",
      "Epoch 7/60\n",
      " - 0s - loss: 1.2643 - acc: 0.6382\n",
      "Epoch 8/60\n",
      " - 0s - loss: 1.2546 - acc: 0.6425\n",
      "Epoch 9/60\n",
      " - 0s - loss: 1.2605 - acc: 0.6389\n",
      "Epoch 10/60\n",
      " - 0s - loss: 1.2437 - acc: 0.6417\n",
      "Epoch 11/60\n",
      " - 0s - loss: 1.2455 - acc: 0.6375\n",
      "Epoch 12/60\n",
      " - 0s - loss: 1.2406 - acc: 0.6396\n",
      "Epoch 13/60\n",
      " - 0s - loss: 1.2400 - acc: 0.6403\n",
      "Epoch 14/60\n",
      " - 0s - loss: 1.2342 - acc: 0.6425\n",
      "Epoch 15/60\n",
      " - 0s - loss: 1.2324 - acc: 0.6403\n",
      "Epoch 16/60\n",
      " - 0s - loss: 1.2235 - acc: 0.6417\n",
      "Epoch 17/60\n",
      " - 0s - loss: 1.2310 - acc: 0.6432\n",
      "Epoch 18/60\n",
      " - 0s - loss: 1.2218 - acc: 0.6417\n",
      "Epoch 19/60\n",
      " - 0s - loss: 1.2254 - acc: 0.6410\n",
      "Epoch 20/60\n",
      " - 0s - loss: 1.2213 - acc: 0.6439\n",
      "Epoch 21/60\n",
      " - 0s - loss: 1.2201 - acc: 0.6417\n",
      "Epoch 22/60\n",
      " - 0s - loss: 1.2194 - acc: 0.6410\n",
      "Epoch 23/60\n",
      " - 0s - loss: 1.2163 - acc: 0.6460\n",
      "Epoch 24/60\n",
      " - 0s - loss: 1.2166 - acc: 0.6403\n",
      "Epoch 25/60\n",
      " - 0s - loss: 1.2128 - acc: 0.6432\n",
      "Epoch 26/60\n",
      " - 0s - loss: 1.2186 - acc: 0.6432\n",
      "Epoch 27/60\n",
      " - 0s - loss: 1.2198 - acc: 0.6353\n",
      "Epoch 28/60\n",
      " - 0s - loss: 1.2112 - acc: 0.6417\n",
      "Epoch 29/60\n",
      " - 0s - loss: 1.2117 - acc: 0.6410\n",
      "Epoch 30/60\n",
      " - 0s - loss: 1.2086 - acc: 0.6403\n",
      "Epoch 31/60\n",
      " - 0s - loss: 1.2097 - acc: 0.6417\n",
      "Epoch 32/60\n",
      " - 0s - loss: 1.2070 - acc: 0.6425\n",
      "Epoch 33/60\n",
      " - 0s - loss: 1.2068 - acc: 0.6417\n",
      "Epoch 34/60\n",
      " - 0s - loss: 1.2057 - acc: 0.6439\n",
      "Epoch 35/60\n",
      " - 0s - loss: 1.2061 - acc: 0.6439\n",
      "Epoch 36/60\n",
      " - 0s - loss: 1.2002 - acc: 0.6432\n",
      "Epoch 37/60\n",
      " - 0s - loss: 1.2032 - acc: 0.6432\n",
      "Epoch 38/60\n",
      " - 0s - loss: 1.2067 - acc: 0.6396\n",
      "Epoch 39/60\n",
      " - 0s - loss: 1.1992 - acc: 0.6432\n",
      "Epoch 40/60\n",
      " - 0s - loss: 1.1984 - acc: 0.6446\n",
      "Epoch 41/60\n",
      " - 0s - loss: 1.2024 - acc: 0.6481\n",
      "Epoch 42/60\n",
      " - 0s - loss: 1.1981 - acc: 0.6439\n",
      "Epoch 43/60\n",
      " - 0s - loss: 1.2003 - acc: 0.6396\n",
      "Epoch 44/60\n",
      " - 0s - loss: 1.2019 - acc: 0.6432\n",
      "Epoch 45/60\n",
      " - 0s - loss: 1.1977 - acc: 0.6425\n",
      "Epoch 46/60\n",
      " - 0s - loss: 1.1945 - acc: 0.6467\n",
      "Epoch 47/60\n",
      " - 0s - loss: 1.2002 - acc: 0.6439\n",
      "Epoch 48/60\n",
      " - 0s - loss: 1.1943 - acc: 0.6460\n",
      "Epoch 49/60\n",
      " - 0s - loss: 1.1928 - acc: 0.6467\n",
      "Epoch 50/60\n",
      " - 0s - loss: 1.2009 - acc: 0.6460\n",
      "Epoch 51/60\n",
      " - 0s - loss: 1.1918 - acc: 0.6460\n",
      "Epoch 52/60\n",
      " - 0s - loss: 1.1916 - acc: 0.6432\n",
      "Epoch 53/60\n",
      " - 0s - loss: 1.1941 - acc: 0.6474\n",
      "Epoch 54/60\n",
      " - 0s - loss: 1.1929 - acc: 0.6474\n",
      "Epoch 55/60\n",
      " - 0s - loss: 1.1880 - acc: 0.6460\n",
      "Epoch 56/60\n",
      " - 0s - loss: 1.1888 - acc: 0.6453\n",
      "Epoch 57/60\n",
      " - 0s - loss: 1.1867 - acc: 0.6481\n",
      "Epoch 58/60\n",
      " - 0s - loss: 1.1870 - acc: 0.6460\n",
      "Epoch 59/60\n",
      " - 0s - loss: 1.1857 - acc: 0.6460\n",
      "Epoch 60/60\n",
      " - 0s - loss: 1.1874 - acc: 0.6467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232997d7da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 1.4494285680083578, Accuracy: 0.6439232422090543\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"machine_learning2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Al\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['Hippocampus CA1 pyramidal cell' 'Hippocampus CA1 pyramidal cell'\n",
      " 'Hippocampus CA1 pyramidal cell' 'Hippocampus CA1 pyramidal cell'\n",
      " 'Hippocampus CA1 pyramidal cell']\n",
      "Actual Labels: ['Hippocampus CA1 pyramidal cell', 'Hippocampus CA1 pyramidal cell', 'Hippocampus CA3 pyramidal cell', 'Hippocampus CA1 pyramidal cell', 'Hippocampus CA1 pyramidal cell']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
